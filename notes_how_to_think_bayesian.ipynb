{
 "metadata": {
  "name": "",
  "signature": "sha256:ed4cc705ff64a161512e149470d385553beebf20c9378ba6b3de441421608af8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How to Think Bayesian\n",
      "\n",
      "###Cross Validation\n",
      "* Same Size 100 and 10,000 predictors, classification into 2 groups\n",
      "* Classical regression will fail, too many predictors\n",
      "  * Pick top 10 variables e.g logistic regression\n",
      "  * Cross validation\n",
      "  * What's the problem? It's cheating because self-fufilling. You chose the variables before CV\n",
      "  * Should not use the entire dataset. Spilt them up into Train, Validation, Test set!\n",
      "* Goals of CV:\n",
      "  * Model selection/tuning \n",
      "  * Model assessment\n",
      "\n",
      "###Fundamental Questions\n",
      "* Where is the info coming from?\n",
      "* What should you condition on, what should you let random?\n",
      "\n",
      "###Bayesian Basics\n",
      "* Bayes' Rule is not Bayesian Stats\n",
      "* Model: $f(y \\mid \\theta)$, y is data, $\\theta$ is parameter, f() is density\n",
      "* Bayesian: $\\pi(\\theta \\mid y)$ posterior distribution, distribution of the unknown paramaters given the data\n",
      "  * Everything is a random variable - assign a probability distribution \n",
      "* Freq: $f(y \\mid \\theta)$y is fixed, $\\theta$ unknown, they say there is not distribution of $\\theta$\n",
      "* No 1 approach is best\n",
      "\n",
      "$$\n",
      "\\begin{align}\n",
      " P( A | X ) = & \\frac{ P(X | A) P(A) } {P(X) } \\\\\\\\[5pt]\n",
      "& \\propto P(X | A) P(A)\\;\\; (\\propto \\text{is proportional to } )\n",
      "\\end{align}\n",
      "$$\n",
      "\n",
      "* MCMC - a way to do bayesian computation based on markov chain\n",
      "* Choice of prior is the problem\n",
      "\n",
      "$P( A | X ) \\propto P(X | A) P(A)$\n",
      "###* posterior $\\propto$ likelihood X prior\n",
      "* treat X as a constant\n",
      "* proportional means there's a constant\n",
      "* MLE: Maximum Likelihood function - look for the highest peak in the function\n",
      "* How to estimate $\\theta$? \n",
      "    * Posterior mode (highest peak in function)\n",
      "    * Posterior mean\n",
      "    * Interval estimation - Credible Interval\n",
      "* Do not just use the MLE, plot the function\n",
      "* Jeffrey's prior - not sure what's the prior\n",
      "* If enough data, does not matter what prior. If little data, no stats will be very accurate\n",
      "* Deciding a prior is personal belief\n",
      "* If sample size is large, any prior is not going to make much of difference\n",
      "\n",
      "###Conjugate Prior\n",
      "* Posterior distribution is the same distribution as the prior\n",
      "* We have a few distribution we can pick\n",
      "* Example: Binomial, y ~ Bin(n,p), estimate p, p ~ Beta(a,b)\n",
      "* Example: Normal distribution y ~ N(m,v), estimate v\n",
      "* Conjugate: if we observe the prior distribution as normal, the posterior is also normal\n",
      "* Posterior mean = weighted average of data mean and prior mean\n",
      "* Follow the likelihood function. Choose the prior to look like likelihood.\n",
      "* MCMC - run a simulation, create a histogram of draws of the posterior distribution. You want the mean of posteriod? Just look at mean of histogram.\n",
      "\n",
      "\n",
      " \n",
      "  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}